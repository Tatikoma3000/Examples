{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd755399",
   "metadata": {},
   "source": [
    "### Создание модели FastText для поиска наиболее релевантной шутки к введенному пользователем запросу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bf93d",
   "metadata": {},
   "source": [
    "##### 1. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ffa016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from stop_words import get_stop_words\n",
    "import razdel\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import dill\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca23d4f",
   "metadata": {},
   "source": [
    "##### 2. Подготовка к препроцессингу датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc8b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Chat-bot\\jokes\\df.csv', sep='\\t', encoding='utf-8')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197fe661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'0':'question_answer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e330650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размерность вектора эмбеддингов для слов\n",
    "embedding_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2a8552c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импорт знаков пунктуации для препроцессинга\n",
    "punctuations = string.punctuation\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e10e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего найдено 422 стоп-слов\n"
     ]
    }
   ],
   "source": [
    "# Импорт Стоп-слов\n",
    "stop_words = get_stop_words('ru')\n",
    "stops = nltk.corpus.stopwords.words('russian')\n",
    "stop_words.extend(stops)\n",
    "stop_words = list(set(stop_words))\n",
    "print(f'Всего найдено {len(stop_words)} стоп-слов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0668f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142d6251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Как водичка ?;;; А я здесь как женшина сижу, а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Я затрудняюсь поставить вам диагноз ... Наверн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что такое дефицит в маркистском понимании?;;; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Можно у вас срочно отремонтировать часы?;;; Не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Из-за тебя я проиграл уйму денег!;;; Почему ты...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87715</th>\n",
       "      <td>Дорогая, выходи за меня замуж.;;; А что ты мне...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87716</th>\n",
       "      <td>Поздравляем! У вас сегодня родились сразу три ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87717</th>\n",
       "      <td>Что ты там делаешь, сынок?;;; Не сейчас, мам!;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87718</th>\n",
       "      <td>Алло, милиция?!;;; Да!;;; Быстрее приезжайте, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87719</th>\n",
       "      <td>Пап, я в пятницу на свадьбу иду, дай денег.;;;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87720 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question_answer\n",
       "0      Как водичка ?;;; А я здесь как женшина сижу, а...\n",
       "1      Я затрудняюсь поставить вам диагноз ... Наверн...\n",
       "2      Что такое дефицит в маркистском понимании?;;; ...\n",
       "3      Можно у вас срочно отремонтировать часы?;;; Не...\n",
       "4      Из-за тебя я проиграл уйму денег!;;; Почему ты...\n",
       "...                                                  ...\n",
       "87715  Дорогая, выходи за меня замуж.;;; А что ты мне...\n",
       "87716  Поздравляем! У вас сегодня родились сразу три ...\n",
       "87717  Что ты там делаешь, сынок?;;; Не сейчас, мам!;...\n",
       "87718  Алло, милиция?!;;; Да!;;; Быстрее приезжайте, ...\n",
       "87719  Пап, я в пятницу на свадьбу иду, дай денег.;;;...\n",
       "\n",
       "[87720 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['question_answer'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb9f80",
   "metadata": {},
   "source": [
    "##### 3. Препроцессинг: удаление знаков пунктуаций, эмоджи, чисел и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d9ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text:str, punctuations=punctuations, stop_words=stop_words, morph=morph_analyzer):\n",
    "    \n",
    "    text = str(text)\n",
    "    text = text.lower()                 # Изменяем регистр на нижний\n",
    "    \n",
    "    # Замена пунктуации пробелами:\n",
    "    for el in string.punctuation:\n",
    "        text = text.replace(el, ' ')\n",
    "    \n",
    "#    # Замена специальных символов на пробелы\n",
    "#    text = re.sub(r'[^a-Za-Z0-9]', ' ', text)\n",
    "#    print(text)\n",
    "\n",
    "    # Удаляем эмоджи из текста\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'a', text)\n",
    "    \n",
    "    # Сличение частицы \"не\" с глаголом\n",
    "    text = re.sub(r'не ', r'не', text)\n",
    "\n",
    "    # Замена чисел на пробелы\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "   \n",
    "    # Удаляем слова длиной в 1 символ\n",
    "    # Удаляем слова из словаря стоп-слов\n",
    "    # Получаем нормальную форму слова\n",
    "    text = ' '.join([morph.parse(w)[0].normal_form for w in text.split() if len(w)>1 and w not in stop_words])\n",
    "  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b8e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87720/87720 [02:48<00:00, 521.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Препроцессинг\n",
    "df['preprocessed'] = df['question_answer'].progress_apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c126441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87720/87720 [00:06<00:00, 14265.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Токенезация\n",
    "df['tokenized'] = df['preprocessed'].progress_apply(lambda x: [_.text for _ in  list(razdel.tokenize(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1cd086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Максимальное количество значимых токенов в предложении\n",
    "df['количество токенов'] = df['tokenized'].apply(lambda x: len(x))\n",
    "df['количество токенов'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40cf976b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87651, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удаление предложений с количеством значимых токенов = 0\n",
    "df = df[df['количество токенов'] > 0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2da48",
   "metadata": {},
   "source": [
    "##### 4. Сохранение подготовленного датасета на диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c612aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\Chat-bot\\jokes\\df_preprocessed.dill', 'wb') as f:\n",
    "    dill.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edf20c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\Chat-bot\\jokes\\df_preprocessed.dill', 'rb') as f:\n",
    "    df = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971cd1ab",
   "metadata": {},
   "source": [
    "##### 5. Обучение модели FastText. Сохранение обученной модели на диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d191e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [el for el in df[df['количество токенов'] > 1]['tokenized'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(sentences=sentences, vector_size=embedding_dim, window=5, min_count=3)  # instantiate\n",
    "#model.build_vocab(corpus_iterable=df['question_tokenized'].values.tolist())\n",
    "model.train(corpus_iterable=df[df['количество токенов'] > 1]['tokenized'].values.tolist(), total_examples=df.shape[0], epochs=10)  # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c208112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'D:\\Chat-bot\\jokes\\fastetx_model_1.fst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d3b6a",
   "metadata": {},
   "source": [
    "##### 6. Получение эмбеддинга запроса пользователя. Получение наиболее релевантного ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27d7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load(r'D:\\Chat-bot\\jokes\\fastetx_model_1.fst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5187ad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87651/87651 [00:05<00:00, 14695.28it/s]\n"
     ]
    }
   ],
   "source": [
    "def words_to_embeddings(mas:list):\n",
    "    vector = np.zeros(embedding_dim)\n",
    "    i = 0\n",
    "    for word in mas:\n",
    "        i += 1\n",
    "        vector += model.wv[word]\n",
    "    return vector/i\n",
    "        \n",
    "df['sentence_embeddings'] = df['tokenized'].progress_apply(lambda x: words_to_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad86e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_between_vectors(i, j):\n",
    "    dot_product = np.dot(i, j)\n",
    "    magnitude1 = np.linalg.norm(i)\n",
    "    magnitude2 = np.linalg.norm(j)\n",
    "    angle = np.arccos(dot_product / (magnitude1 * magnitude2))\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3d12a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87651/87651 [00:00<00:00, 87712.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Танечка, у тебя есть недвижимость на берегу моря?\n",
      "Есть один поклонник, только он совсем старый.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'шутка про море'\n",
    "text=preprocess_text(text)\n",
    "text = [_.text for _ in list(razdel.tokenize(text))]\n",
    "text = words_to_embeddings(text)\n",
    "\n",
    "computing = df['sentence_embeddings'].progress_apply(lambda x: compute_distance_between_vectors(x, text))\n",
    "indexes = computing.sort_values(ascending=True).head(5).index.tolist()\n",
    "random.shuffle(indexes)\n",
    "reply = ''\n",
    "\n",
    "cur_answer = df.loc[indexes[0], 'question_answer']\n",
    "print(cur_answer.replace(';;; ', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5ce3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
