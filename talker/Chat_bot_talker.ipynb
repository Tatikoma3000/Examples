{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4e6298",
   "metadata": {},
   "source": [
    "### Создание кастомной модели FastText для поддержания диалога чат-ботом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a8454",
   "metadata": {},
   "source": [
    "##### 1. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabdb05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lazar\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from stop_words import get_stop_words\n",
    "import razdel\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "import random\n",
    "import dill\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0db869",
   "metadata": {},
   "source": [
    "##### 2. Подготовка к препроцессингу датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598c2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размерность вектора эмбеддингов для слов\n",
    "embedding_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cc0b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импорт знаков пунктуации для препроцессинга\n",
    "punctuations = string.punctuation\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b535cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего найдено 422 стоп-слов\n"
     ]
    }
   ],
   "source": [
    "# Импорт Стоп-слов\n",
    "stop_words = get_stop_words('ru')\n",
    "stops = nltk.corpus.stopwords.words('russian')\n",
    "stop_words.extend(stops)\n",
    "stop_words = list(set(stop_words))\n",
    "print(f'Всего найдено {len(stop_words)} стоп-слов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa76e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f9e66",
   "metadata": {},
   "source": [
    "##### Чтение датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1й датасет\n",
    "df = pd.read_csv(r'D:\\Chat-bot\\talker\\talker.csv', sep='\\t', encoding='utf-8')\n",
    "df.drop(columns=['Unnamed: 0', 'short_phrase'], inplace=True)\n",
    "df.rename(columns={'expanded_phrase':'answer', 'context':'question'}, inplace=True)\n",
    "df['answer'] = df['answer'].apply(lambda x: f\"{x[0].upper()}{x[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3й датасет\n",
    "df_3 = pd.read_csv(r'D:\\Chat-bot\\talker\\talker_3.csv', sep='\\t', encoding='utf-8')\n",
    "df_3.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_3['answer'] = df_3['answer'].apply(lambda x: f\"{str(x)[0].upper()}{str(x)[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889627dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.concat([df, df_2, df_3], axis=0, ignore_index=True)\n",
    "df = pd.concat([df, df_3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace69e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['question'].notnull()]\n",
    "df = df[df['answer'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f0009",
   "metadata": {},
   "source": [
    "##### 3. Препроцессинг: удаление знаков пунктуаций, эмоджи, чисел и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60587d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text:str, punctuations=punctuations, stop_words=stop_words, morph=morph_analyzer):\n",
    "    \n",
    "    text = str(text)\n",
    "    text = text.lower()                 # Изменяем регистр на нижний\n",
    "    \n",
    "    # Замена пунктуации пробелами:\n",
    "    for el in string.punctuation:\n",
    "        text = text.replace(el, ' ')\n",
    "    \n",
    "#    # Замена специальных символов на пробелы\n",
    "#    text = re.sub(r'[^a-Za-Z0-9]', ' ', text)\n",
    "#    print(text)\n",
    "\n",
    "    # Удаляем эмоджи из текста\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'a', text)\n",
    "    \n",
    "    # Сличение частицы \"не\" с глаголом\n",
    "    text = re.sub(r'не ', r'не', text)\n",
    "\n",
    "    # Замена чисел на пробелы\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "   \n",
    "    # Удаляем слова длиной в 1 символ\n",
    "    # Удаляем слова из словаря стоп-слов\n",
    "    # Получаем нормальную форму слова\n",
    "    text = ' '.join([morph.parse(w)[0].normal_form for w in text.split() if len(w)>1 and w not in stop_words])\n",
    "  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Препроцессинг\n",
    "df['question_preprocessed'] = df['question'].progress_apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенезация\n",
    "df['question_tokenized'] = df['question_preprocessed'].progress_apply(lambda x: [_.text for _ in  list(razdel.tokenize(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Максимальное количество значимых токенов в предложении\n",
    "df['количество токенов'] = df['question_tokenized'].apply(lambda x: len(x))\n",
    "df['количество токенов'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8451d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление предложений с количеством значимых токенов = 0\n",
    "df = df[df['количество токенов'] > 0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем слова-ассоциации:\n",
    "associations = pd.read_csv(r'D:\\Chat-bot\\associations\\associations.csv', encoding='utf-8', sep='\\t')\n",
    "associations.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f7d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "associations['question_preprocessed'] = associations['0'].progress_apply(lambda x: preprocess_text(x))\n",
    "associations['question_tokenized'] = associations['question_preprocessed'].progress_apply(lambda x: [_.text for _ in list(razdel.tokenize(x))])\n",
    "associations['количество токенов'] = associations['question_tokenized'].apply(lambda x: len(x))\n",
    "associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13550027",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [el for el in df[df['количество токенов'] > 1]['question_tokenized'].values.tolist()]\n",
    "sentences.extend([el for el in associations[associations['количество токенов'] > 1]['question_tokenized'].values.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b30db",
   "metadata": {},
   "source": [
    "##### 4. Сохранение подготовленного датасета на диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43602739",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\Chat-bot\\talker\\df_preprocessed.dill', 'wb') as f:\n",
    "    dill.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e60cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\Chat-bot\\talker\\df_preprocessed.dill', 'rb') as f:\n",
    "    df = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28001a52",
   "metadata": {},
   "source": [
    "##### 5. Обучение модели FastText. Сохранение обученной модели на диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46653320",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(sentences=sentences, vector_size=embedding_dim, window=2, min_count=1)  # instantiate\n",
    "#model.build_vocab(corpus_iterable=df['question_tokenized'].values.tolist())\n",
    "model.train(corpus_iterable=df[df['количество токенов'] > 1]['question_tokenized'].values.tolist(), total_examples=df.shape[0], epochs=10)  # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c05b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'D:\\Chat-bot\\talker\\fastetx_talker_model_2.fst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4dfc0",
   "metadata": {},
   "source": [
    "##### 6. Получение эмбеддинга запроса пользователя. Получение наиболее релевантного ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c9c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load(r'D:\\Chat-bot\\talker\\fastetx_talker_model_2.fst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b1e0fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136054/136054 [00:03<00:00, 40427.45it/s]\n"
     ]
    }
   ],
   "source": [
    "def words_to_embeddings(mas:list):\n",
    "    vector = np.zeros(embedding_dim)\n",
    "    i = 0\n",
    "    for word in mas:\n",
    "        i += 1\n",
    "        vector += model.wv[word]\n",
    "    return vector/i\n",
    "        \n",
    "df['sentence_embeddings'] = df['question_tokenized'].progress_apply(lambda x: words_to_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7071f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_between_vectors(i, j):\n",
    "    dot_product = np.dot(i, j)\n",
    "    magnitude1 = np.linalg.norm(i)\n",
    "    magnitude2 = np.linalg.norm(j)\n",
    "    angle = np.arccos(dot_product / (magnitude1 * magnitude2))\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7dd12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136054/136054 [00:01<00:00, 73268.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Привет! Все хорошо, спасибо. А у тебя?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Привет! Как дела?'\n",
    "text=preprocess_text(text)\n",
    "text = [_.text for _ in list(razdel.tokenize(text))]\n",
    "text = words_to_embeddings(text)\n",
    "\n",
    "computing = df['sentence_embeddings'].progress_apply(lambda x: compute_distance_between_vectors(x, text))\n",
    "index = random.choice(computing.sort_values(ascending=True).head(5).index)\n",
    "df.loc[index, 'answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc37c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
